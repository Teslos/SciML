{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8910dfe0-2509-4a4a-afbd-d66a9e09c12e",
   "metadata": {},
   "source": [
    "# Problem\n",
    "The new test for solving pde using pytorch:\n",
    "\n",
    "$\n",
    "\\frac{\\partial{u}}{\\partial t} = \\kappa (\\frac{\\partial^2 u}{\\partial{x}^2}+\\frac{\\partial^2 u}{\\partial{y}^2}) + S(x,y,t)\n",
    "$\n",
    "\n",
    "in the square region $0 \\le x \\le 2$ and $ 0 \\le y \\le 2$\n",
    "for the time $0 \\le t \\le 2$\n",
    "\n",
    "Independent variables:\n",
    "* t - time\n",
    "* x - coordinate\n",
    "* y - coordinate\n",
    "\n",
    "Dependent variables output:\n",
    "* u - diffusion species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a91bb9-9e19-47d7-8d0a-8404b5ebb343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5823ac0-119e-4ac4-ad8d-e7dd2b915c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c1231bc-16dd-4528-8e08-cea8940024a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4096\n",
    "block_size = 8\n",
    "batch_size * block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a37080f-0a0a-42a9-ba51-6f922d99ef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random subset of the coordinates for the mini-batch\n",
    "x = torch.arange(0, 0.1 + 0.001, 0.001)\n",
    "num_samples = x.shape[0]\n",
    "perm = torch.randperm(num_samples)[:batch_size]\n",
    "minibatch_coords = x[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9b12e97-d873-4ac6-ae5c-714b5f3be689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0880, 0.0300, 0.0890, 0.0150, 0.0390, 0.0500, 0.0680, 0.0710, 0.0730,\n",
       "        0.0490, 0.0990, 0.0440, 0.0610, 0.0340, 0.0050, 0.0190, 0.0540, 0.0070,\n",
       "        0.0790, 0.0900, 0.0800, 0.0060, 0.0620, 0.0180, 0.0460, 0.0330, 0.0350,\n",
       "        0.0200, 0.0030, 0.0290, 0.0240, 0.0120, 0.0820, 0.0940, 0.0400, 0.0630,\n",
       "        0.0590, 0.0670, 0.0950, 0.0320, 0.0110, 0.0080, 0.0550, 0.0650, 0.0310,\n",
       "        0.0040, 0.0140, 0.0700, 0.0660, 0.0100, 0.0160, 0.0580, 0.0420, 0.0970,\n",
       "        0.0980, 0.0480, 0.0740, 0.0250, 0.0600, 0.0360, 0.0370, 0.0640, 0.0520,\n",
       "        0.0410, 0.0430, 0.0960, 0.0570, 0.0810, 0.0170, 0.0760, 0.0720, 0.0270,\n",
       "        0.0010, 0.0930, 0.0230, 0.0840, 0.0380, 0.0870, 0.0210, 0.0470, 0.0860,\n",
       "        0.0130, 0.0560, 0.0280, 0.0910, 0.0020, 0.0780, 0.0260, 0.0770, 0.0830,\n",
       "        0.0090, 0.0530, 0.0920, 0.0850, 0.0450, 0.0750, 0.0220, 0.0690, 0.0000,\n",
       "        0.0510, 0.1000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bebd0b79-1363-46a0-96a8-0f9548acc145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewrite in layer, this is rather boilplate code \n",
    "class DiffNet(nn.Module):\n",
    "    def __init__(self, input_size,hidden_size,\n",
    "                output_size, depth, act=torch.nn.Tanh):\n",
    "        super(DiffNet, self).__init__()\n",
    "        \n",
    "        layers = [('input', torch.nn.Linear(input_size, hidden_size))]\n",
    "        layers.append(('input_activation', act()))\n",
    "        for i in range(depth):\n",
    "            layers.append(\n",
    "                ('hidden_%d' %i, torch.nn.Linear(hidden_size, hidden_size))\n",
    "            )\n",
    "            layers.append(('activation_%d' %i,act()))\n",
    "        layers.append(('output', torch.nn.Linear(hidden_size, output_size)))\n",
    "        \n",
    "        layerDict = OrderedDict(layers)\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        out = self.layers(X)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d246b2d-7335-499d-a059-40aec01436e8",
   "metadata": {},
   "source": [
    "## New layer architecture (Giulio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edc352ec-8c36-44c9-ae08-8a35197c3f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexHeatEquationNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplexHeatEquationNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(3, 512)\n",
    "        self.ln1 = torch.nn.LayerNorm(512)\n",
    "        self.silu1 = torch.nn.SiLU()\n",
    "        self.fc2 = torch.nn.Linear(512, 256)\n",
    "        self.ln2 = torch.nn.LayerNorm(256)\n",
    "        self.silu2 = torch.nn.SiLU()\n",
    "        self.fc3 = torch.nn.Linear(256, 128)\n",
    "        self.ln3 = torch.nn.LayerNorm(128)\n",
    "        self.silu3 = torch.nn.SiLU()\n",
    "        self.fc4 = torch.nn.Linear(128, 64)\n",
    "        self.ln4 = torch.nn.LayerNorm(64)\n",
    "        self.silu4 = torch.nn.SiLU()\n",
    "        self.fc5 = torch.nn.Linear(64, 32)\n",
    "        self.ln5 = torch.nn.LayerNorm(32)\n",
    "        self.silu5 = torch.nn.SiLU()\n",
    "        self.fc6 = torch.nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        x = self.silu1(self.ln1(self.fc1(X)))\n",
    "        x = self.silu2(self.ln2(self.fc2(x)))\n",
    "        x = self.silu3(self.ln3(self.fc3(x)))\n",
    "        x = self.silu4(self.ln4(self.fc4(x)))\n",
    "        x = self.silu5(self.ln5(self.fc5(x)))\n",
    "        x = self.fc6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e80a2b9-613f-4211-92a3-2fef6fabca81",
   "metadata": {},
   "source": [
    "Material properties for this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab6de308-09d6-4682-8d02-d37f1f2f15b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ρ = 7860; Cp = 624; k = 30.1\n",
    "γ = 2.5e+4; P = 1e+2; r0 = 0.05; y_min=0.0; y_max = 0.1; x_min = 0.0; x_max = 0.1;\n",
    "κ = k/(ρ * Cp)\n",
    "T0 = 300.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0265deb-6f92-4c67-9877-37cf9e77dfd8",
   "metadata": {},
   "source": [
    "Differential model for this equation is very similar as for one-dimensional case.\n",
    "* predict out based on the coordinates $x, y$ and time $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c7606c8-601f-470d-a4f3-6b75059837fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 0.01\n",
    "class Net:\n",
    "    def __init__(self):\n",
    "        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        #device = \"cpu\"\n",
    "        # build model\n",
    "        # self.model = DiffNet(\n",
    "        #        input_size=3,\n",
    "        #        hidden_size=128,\n",
    "        #        output_size=1,\n",
    "        #        depth=5,\n",
    "        #        act=torch.nn.Tanh).to(device)\n",
    "        self.model = ComplexHeatEquationNet().to(device)\n",
    "        # Initial and boundary conditions, we first create the \n",
    "        # meshgrid for x and y coordinates. The mesh is regular \n",
    "        # grid with h and k steps.\n",
    "        self.h = 0.01\n",
    "        self.k = 0.01\n",
    "        self.dt = 0.01\n",
    "        \n",
    "        x = torch.arange(0, 0.1 + self.h, self.h)\n",
    "        y = torch.arange(0, 0.1 + self.k, self.k)\n",
    "        t = torch.arange(0, 0.1 + self.dt, self.dt)\n",
    "        \n",
    "        \n",
    "        xmin_bc = torch.stack(torch.meshgrid(x[0],y,t)).reshape(3,-1).T\n",
    "        xmax_bc = torch.stack(torch.meshgrid(x[-1],y,t)).reshape(3,-1).T\n",
    "        ymin_bc = torch.stack(torch.meshgrid(x,y[0],t)).reshape(3,-1).T\n",
    "        ymax_bc = torch.stack(torch.meshgrid(x,y[-1],t)).reshape(3,-1).T\n",
    "        print(f\"xmin_bc requires grad: {xmin_bc.is_leaf}\")\n",
    "        ic = torch.stack(torch.meshgrid(x,y,t[0])).reshape(3,-1).T\n",
    "        \n",
    "        # make training bcs\n",
    "        # self.bc_train = torch.cat([ic, xmin_bc, xmax_bc, ymin_bc, ymax_bc]) @ivt note this are all boundary conditions\n",
    "        self.bc_train = torch.cat([ic, xmin_bc, xmax_bc, ymin_bc])\n",
    "        self.bc_train = self.bc_train.to(device)\n",
    "        print(f\"bc_train : {self.bc_train.shape}\")\n",
    "        \n",
    "        self.X = torch.stack(torch.meshgrid(x,y,t)).reshape(3,-1).T.to(device)\n",
    "        self.X.requires_grad = True\n",
    "        print(f\"X shape: {self.X.shape}\")\n",
    "        \n",
    "        self.all_zeros = torch.zeros_like(self.X).to(device)\n",
    "        self.all_zeros.requires_grad = False\n",
    "        \n",
    "        #initial and boundary condition \n",
    "        u_init = torch.zeros(len(ic))\n",
    "        u_xmin = torch.ones(len(xmin_bc))*T0\n",
    "        u_xmax = torch.ones(len(xmax_bc))*T0\n",
    "        u_ymin = torch.ones(len(ymax_bc))*T0\n",
    "        u_ymax = torch.ones(len(ymin_bc))*T0\n",
    "        \n",
    "        # self.u_train = torch.cat([u_init, u_xmin, u_xmax, u_ymin, u_ymax])\n",
    "        self.u_train = torch.cat([u_init, u_xmin, u_xmax, u_ymin])\n",
    "        self.u_train = self.u_train.unsqueeze(1)\n",
    "        self.u_train = self.u_train.to(device)\n",
    "        \n",
    "        self.mse_cost_function = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.LBFGS(self.model.parameters(),lr=learn_rate,max_iter=500,max_eval=50000,\n",
    "                                  history_size=50,tolerance_grad=1e-5,tolerance_change=1.0 * np.finfo(float).eps)\n",
    "        self.optimizer_Adam = torch.optim.Adam(self.model.parameters())\n",
    "        self.iter = 0\n",
    "        \n",
    "    def source(self): \n",
    "        return 2*P/(torch.pi*r0**2)*torch.exp(-2/(r0**2)*((self.X[:,0]-self.X[:,2]*0.02)**2 + (self.X[:,1]-y_max/2)**2))\n",
    "\n",
    "    def f(self):\n",
    "        u = self.model(self.X) \n",
    "             \n",
    "        u_dX = torch.autograd.grad(\n",
    "            u, self.X, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        u_x = u_dX[:,0]\n",
    "        u_y = u_dX[:,1]\n",
    "        u_t = u_dX[:,2]\n",
    "        \n",
    "       \n",
    "        \n",
    "        u_dXX = torch.autograd.grad(\n",
    "            u_dX, self.X, \n",
    "            grad_outputs=torch.ones_like(u_dX),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        u_xx = u_dXX[:,0]\n",
    "        u_yy = u_dXX[:,1]\n",
    "        \n",
    "        return u_t - κ*u_xx - κ*u_yy - self.source()\n",
    "    \n",
    "    def loss_func(self):\n",
    "        self.optimizer.zero_grad()\n",
    "        # initial and boundary conditions\n",
    "        out = self.model(self.bc_train)\n",
    "        mse_u = self.mse_cost_function(out, self.u_train)\n",
    "        \n",
    "        # fix condition for PDE\n",
    "        out = self.f()\n",
    "        mse_f = self.mse_cost_function(out, torch.zeros_like(out))\n",
    "    \n",
    "        #loss = mse_u + mse_u_xmax + mse_u_xmin + mse_u_ymax + mse_u_ymin + mse_f\n",
    "        loss = mse_f + mse_u\n",
    "        loss.backward()\n",
    "        \n",
    "        if self.iter % 100 == 0:\n",
    "            print(f\" Iter: {self.iter}, loss:{loss.data}\")\n",
    "            \n",
    "        self.iter += 1\n",
    "        return loss\n",
    "        \n",
    "    def train(self,epochs):\n",
    "        self.ix = torch.randint(0, self.X.shape[0], (batch_size,))\n",
    "        for epoch in range(epochs):\n",
    "            self.optimizer_Adam.step(self.loss_func)\n",
    "        self.optimizer.step(self.loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4073b86-69c1-45af-b7e5-c56bd5cb4dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xmin_bc requires grad: True\n",
      "bc_train : torch.Size([484, 3])\n",
      "X shape: torch.Size([1331, 3])\n",
      " Iter: 0, loss:66726972.0\n",
      " Iter: 100, loss:66044936.0\n",
      " Iter: 200, loss:66724600.0\n",
      " Iter: 300, loss:66724096.0\n",
      " Iter: 400, loss:65742708.0\n",
      " Iter: 500, loss:64465124.0\n",
      " Iter: 600, loss:62915512.0\n",
      " Iter: 700, loss:61271472.0\n",
      " Iter: 800, loss:59551592.0\n",
      " Iter: 900, loss:57840656.0\n",
      " Iter: 1000, loss:58014444.0\n",
      " Iter: 1100, loss:53608064.0\n",
      " Iter: 1200, loss:51627116.0\n",
      " Iter: 1300, loss:52616732.0\n",
      " Iter: 1400, loss:47544120.0\n",
      " Iter: 1500, loss:45669744.0\n",
      " Iter: 1600, loss:43746920.0\n",
      " Iter: 1700, loss:44258520.0\n",
      " Iter: 1800, loss:40186056.0\n",
      " Iter: 1900, loss:38749804.0\n",
      " Iter: 2000, loss:36875624.0\n",
      " Iter: 2100, loss:35719132.0\n",
      " Iter: 2200, loss:34903828.0\n",
      " Iter: 2300, loss:31670706.0\n",
      " Iter: 2400, loss:31385706.0\n",
      " Iter: 2500, loss:36916280.0\n",
      " Iter: 2600, loss:28061392.0\n",
      " Iter: 2700, loss:24899614.0\n",
      " Iter: 2800, loss:42213912.0\n",
      " Iter: 2900, loss:23794578.0\n",
      " Iter: 3000, loss:21455264.0\n",
      " Iter: 3100, loss:19512496.0\n",
      " Iter: 3200, loss:18131846.0\n",
      " Iter: 3300, loss:20377408.0\n",
      " Iter: 3400, loss:16088807.0\n",
      " Iter: 3500, loss:16876926.0\n",
      " Iter: 3600, loss:15987739.0\n",
      " Iter: 3700, loss:11381405.0\n",
      " Iter: 3800, loss:11418941.0\n",
      " Iter: 3900, loss:8973942.0\n",
      " Iter: 4000, loss:11337345.0\n",
      " Iter: 4100, loss:9640366.0\n",
      " Iter: 4200, loss:8271561.0\n",
      " Iter: 4300, loss:8327978.0\n",
      " Iter: 4400, loss:6086142.0\n",
      " Iter: 4500, loss:5097955.5\n",
      " Iter: 4600, loss:4553281.0\n",
      " Iter: 4700, loss:5675426.5\n",
      " Iter: 4800, loss:4007307.5\n",
      " Iter: 4900, loss:3354432.5\n",
      " Iter: 5000, loss:3487291.5\n",
      " Iter: 5100, loss:2696869.5\n",
      " Iter: 5200, loss:2177452.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13916\\1583840499.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13916\\2997981230.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_Adam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'differentiable'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13916\\2997981230.py\u001b[0m in \u001b[0;36mloss_func\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;31m# fix condition for PDE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[0mmse_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_cost_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13916\\2997981230.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         u_dXX = torch.autograd.grad(\n\u001b[0m\u001b[0;32m     84\u001b[0m             \u001b[0mu_dX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0mgrad_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu_dX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_vmap_internals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_none_pass_through\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_outputs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    301\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             allow_unused, accumulate_grad=False)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.train(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f347e9-50cf-4b1c-a2ed-f35c4393d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6da819ee-b071-4026-beb3-5b61570b0594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112e3da5-a17d-4696-a3c3-57f5e807c09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(0,0.1,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e845d54-5d2b-4314-a19d-c2a16028c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "dx = 0.005\n",
    "x = torch.arange(0,0.1+dx,dx)\n",
    "y = torch.arange(0,0.1+dx,dx)\n",
    "t = torch.ones_like(x)*0.1\n",
    "X = torch.stack(torch.meshgrid(x,y,t)).reshape(3,-1).T.to(device)\n",
    "\n",
    "\n",
    "u_pred = net.model(X)\n",
    "um = u_pred.data.cpu().numpy()\n",
    "um = um.reshape(21,21,21)\n",
    "\n",
    "x = np.arange(0,0.1+dx,dx)\n",
    "y = np.arange(0,0.1+dx,dx)\n",
    "xm, ym = np.meshgrid(x,y)\n",
    "\n",
    "print(f\"shape: {um.shape}\")\n",
    "\n",
    "surf = ax.plot_surface(xm, ym, um[:,:,3], cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "ax.set_ylabel(\"y coord\")\n",
    "ax.set_xlabel(\"x coord\")\n",
    "fig.colorbar(surf, shrink=.5, aspect=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb1add5-4c2d-4127-8eda-ec8a5c8c136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution(x,y,t):\n",
    "    return np.exp(x + y) * np.cos(x + y + 4*t)\n",
    "anal_sol = solution(x,y,2)\n",
    "mse=np.mean((anal_sol-u_pred.data.cpu().numpy())**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d035d0c7-aa15-426c-aee2-31aadfcb29be",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e15b18c-d26c-4328-b927-40e4eacccabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ee67c3-38e1-4bf6-9b58-be3a9aea23b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875b459e-330b-4a82-a13e-f2fa803f2c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
